{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing results masked inference\n",
    "\n",
    "\n",
    "## remeber in the classification task we got the following results using BERT:\n",
    "\n",
    "- Boolean Connective 100%\n",
    "    \n",
    "- Quantifiers 90.5%\n",
    "\n",
    "- Counting 87.5%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from inference.text_generation.util import num2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc = pd.read_csv(\"results/BC_basic.csv\")\n",
    "# df_q = pd.read_csv()\n",
    "df_count = pd.read_csv(\"results/count_basic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating accuracy from top 10 score\n",
    "features = [\"bert_base_uncased_pre_trained\", \"bert_base_uncased_fine_tuned\"]\n",
    "for feature in features:\n",
    "    df_bc[feature + \"_hard\"] =  np.floor(df_bc[feature].values)\n",
    "    df_count[feature + \"_hard\"] =  np.floor(df_count[feature].values)\n",
    "    \n",
    "\n",
    "\n",
    "def print_score(df_, label_list=None,score=False, acc=True):\n",
    "    pre_trained = df_.bert_base_uncased_pre_trained.values\n",
    "    fine_tuned = df_.bert_base_uncased_fine_tuned.values\n",
    "\n",
    "    print(\"==== General results===\\n\")\n",
    "\n",
    "    if score:\n",
    "        print(\"top 10 score - max = 1.0, min = 0.0\\n\")\n",
    "        print(\"pre_trained: score = {:.1f}\".format(np.mean(pre_trained)))\n",
    "        print(\"fine_tuned: score = {:.1f}\".format(np.mean(fine_tuned)))\n",
    "\n",
    "    pre_trained = df_.bert_base_uncased_pre_trained_hard.values\n",
    "    fine_tuned = df_.bert_base_uncased_fine_tuned_hard.values\n",
    "\n",
    "    if acc:\n",
    "        print(\"\\nAccuracy\")\n",
    "        print(\"pre_trained, acc = {:.1f} %\".format(np.mean(pre_trained)*100))\n",
    "        print(\"fine_tuned, acc = {:.1f} %\".format(np.mean(fine_tuned)*100))\n",
    "\n",
    "    print(\"\\n==== Results for each connective ===\\n\")\n",
    "    \n",
    "    if label_list is None:\n",
    "        label_list = set(df_.label) \n",
    "\n",
    "    for label in label_list:\n",
    "        df_label = df_[df_.label==label]\n",
    "\n",
    "        pre_trained = df_label.bert_base_uncased_pre_trained.values\n",
    "        fine_tuned = df_label.bert_base_uncased_fine_tuned.values\n",
    "        if score:\n",
    "            print(\"top 10 score - max = 1.0, min = 0.0\\n\")\n",
    "            print(\"(label={}) pre_trained: score = {:.1f}\".format(label, np.mean(pre_trained)))\n",
    "            print(\"(label={}) fine_tuned: score = {:.1f}\".format(label, np.mean(fine_tuned)))\n",
    "\n",
    "        pre_trained = df_label.bert_base_uncased_pre_trained_hard.values\n",
    "        fine_tuned = df_label.bert_base_uncased_fine_tuned_hard.values\n",
    "        \n",
    "        if acc:\n",
    "            print(\"\\nAccuracy\\n\")\n",
    "            print(\"(label={}) pre_trained: acc = {:.1f} %\".format(label, np.mean(pre_trained) * 100))\n",
    "            print(\"(label={}) fine_tuned: acc = {:.1f} %\".format(label, np.mean(fine_tuned) * 100))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean connective results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== General results===\n",
      "\n",
      "\n",
      "Accuracy\n",
      "pre_trained, acc = 0.0 %\n",
      "fine_tuned, acc = 55.3 %\n",
      "\n",
      "==== Results for each connective ===\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=or) pre_trained: acc = 0.0 %\n",
      "(label=or) fine_tuned: acc = 80.4 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=and) pre_trained: acc = 0.0 %\n",
      "(label=and) fine_tuned: acc = 30.2 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(df_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifiers results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== General results===\n",
      "\n",
      "\n",
      "Accuracy\n",
      "pre_trained, acc = 4.7 %\n",
      "fine_tuned, acc = 13.2 %\n",
      "\n",
      "==== Results for each connective ===\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=one) pre_trained: acc = 0.0 %\n",
      "(label=one) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=two) pre_trained: acc = 5.2 %\n",
      "(label=two) fine_tuned: acc = 10.3 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=three) pre_trained: acc = 95.7 %\n",
      "(label=three) fine_tuned: acc = 76.1 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=four) pre_trained: acc = 0.0 %\n",
      "(label=four) fine_tuned: acc = 22.8 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=five) pre_trained: acc = 0.0 %\n",
      "(label=five) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=six) pre_trained: acc = 0.0 %\n",
      "(label=six) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=seven) pre_trained: acc = 0.0 %\n",
      "(label=seven) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=eight) pre_trained: acc = 0.0 %\n",
      "(label=eight) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=nine) pre_trained: acc = 0.0 %\n",
      "(label=nine) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=ten) pre_trained: acc = 0.0 %\n",
      "(label=ten) fine_tuned: acc = 14.3 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=eleven) pre_trained: acc = 0.0 %\n",
      "(label=eleven) fine_tuned: acc = 10.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=twelve) pre_trained: acc = 0.0 %\n",
      "(label=twelve) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=thirteen) pre_trained: acc = 0.0 %\n",
      "(label=thirteen) fine_tuned: acc = 39.2 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=fourteen) pre_trained: acc = 0.0 %\n",
      "(label=fourteen) fine_tuned: acc = 16.3 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=fifteen) pre_trained: acc = 0.0 %\n",
      "(label=fifteen) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=sixteen) pre_trained: acc = 0.0 %\n",
      "(label=sixteen) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=seventeen) pre_trained: acc = 0.0 %\n",
      "(label=seventeen) fine_tuned: acc = 100.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=eighteen) pre_trained: acc = 0.0 %\n",
      "(label=eighteen) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=nineteen) pre_trained: acc = 0.0 %\n",
      "(label=nineteen) fine_tuned: acc = 0.0 %\n",
      "\n",
      "\n",
      "Accuracy\n",
      "\n",
      "(label=twenty) pre_trained: acc = 0.0 %\n",
      "(label=twenty) fine_tuned: acc = 0.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerals = list(num2word.values())\n",
    "numerals = [n for n in numerals if n in set(df_count.label)]\n",
    "print_score(df_count, numerals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple BC task:\n",
    "\n",
    "- p = A, B\n",
    "- h = A [mask] B\n",
    "    - [mask] = and \n",
    "\n",
    "- p = A, C\n",
    "- h = A [mask] B\n",
    "    - [mask] = or \n",
    "\n",
    "#### In this notebook we will create a df with columns 'sentence1', 'sentence2', 'sentence2_masked' 'label', and a txt for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from inference.text_generation.vocab import male_names, female_names, cities_and_states, countries\n",
    "from inference.text_generation.util import get_new_item, get_n_different_items\n",
    "from inference.text_generation.util import vi, not_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_entailment(person_list,\n",
    "                   place_list,\n",
    "                   n,\n",
    "                   vi_function,\n",
    "                   not_vi_function,\n",
    "                   mask_token=\"[MASK]\"):\n",
    "    \"\"\"\n",
    "    $P:= pm V(x_1, y_1) , dots, pm V(x_n, y_n)$\n",
    "    $H:= pm V(x_i, y_i) and pm V(x_j, y_j)$\n",
    "    \"\"\"\n",
    "    Subjects = get_n_different_items(person_list, n)\n",
    "    people_O = [get_new_item(Subjects, person_list) for _ in range(n)]\n",
    "    places = get_n_different_items(place_list, n)\n",
    "    Objects = get_n_different_items(people_O + places, n)\n",
    "    fs = np.random.choice([vi_function, not_vi_function], n)\n",
    "    sentence1 = [f(x, y) for f, x, y in zip(fs, Subjects, Objects)]\n",
    "    ids = get_n_different_items(range(len(Subjects)), 2)\n",
    "    sentence2 = sentence1[ids[0]] + \" and \" + sentence1[ids[1]]\n",
    "    sentence2_masked = sentence1[ids[0]] + \" {} \".format(mask_token) + sentence1[ids[1]] \n",
    "    sentence1 = \", \".join(sentence1)\n",
    "    sentence1 += \".\" \n",
    "    label = \"and\"\n",
    "    people_O = list(set(Objects).intersection(people_O))\n",
    "    places = list(set(Objects).intersection(places))\n",
    "    people = \", \".join(Subjects + people_O)\n",
    "    Subjects = \", \".join(Subjects)\n",
    "    Objects = \", \".join(Objects)\n",
    "    places = \", \".join(places)\n",
    "    ids.sort()\n",
    "    ids = \", \".join(map(lambda x: str(x), ids))\n",
    "\n",
    "    return sentence1, sentence2, sentence2_masked, label, Subjects, Objects, ids, people, places\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Andy didn't visit Donald, Cory has visited Olympia.\",\n",
       " \"Cory has visited Olympia and Andy didn't visit Donald\",\n",
       " \"Cory has visited Olympia [MASK] Andy didn't visit Donald\",\n",
       " 'and',\n",
       " 'Andy, Cory',\n",
       " 'Donald, Olympia',\n",
       " '0, 1',\n",
       " 'Andy, Cory, Donald',\n",
       " 'Olympia')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "and_entailment(person_list=male_names,\n",
    "               place_list=cities_and_states,\n",
    "               n=2,\n",
    "               vi_function=vi,\n",
    "               not_vi_function=not_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_entailment(person_list,\n",
    "                  place_list,\n",
    "                  n,\n",
    "                  vi_function,\n",
    "                  not_vi_function,\n",
    "                  mask_token=\"[MASK]\"):\n",
    "    \"\"\"\n",
    "    $P:= pm V(x_1, y_1) , dots, pm V(x_n, y_n)$\n",
    "    $H:= pm V(x_i, y_i) or pm V(x*, y*)$\n",
    "    \"\"\"\n",
    "    Subjects = get_n_different_items(person_list, n)\n",
    "    people_O = [get_new_item(Subjects, person_list) for _ in range(n)]\n",
    "    places = get_n_different_items(place_list, n)\n",
    "    Objects = get_n_different_items(people_O + places, n)\n",
    "    fs = np.random.choice([vi_function, not_vi_function], n)\n",
    "    sentence1 = [f(x, y) for f, x, y in zip(fs, Subjects, Objects)]\n",
    "    fs2 = np.random.choice([vi_function, not_vi_function])\n",
    "    ids = get_n_different_items(range(len(Subjects)), 1)\n",
    "    Subject2 = get_new_item(Subjects + people_O, person_list)\n",
    "    Object2 = [get_new_item(Subjects + people_O + [Subject2], person_list)]\n",
    "    place2 = get_new_item(places, place_list)\n",
    "    Object2 += [place2]\n",
    "    Object2 = np.random.choice(Object2)\n",
    "    sentence2_l = [sentence1[ids[0]], fs2(Subject2, Object2)]\n",
    "    np.random.shuffle(sentence2_l)\n",
    "    sentence2 = sentence2_l[0] + \" or \" + sentence2_l[1]\n",
    "    sentence2_masked = sentence2_l[0] + \" {} \".format(mask_token) + sentence2_l[1] \n",
    "    sentence1 = \", \".join(sentence1)\n",
    "    sentence1 += \".\"\n",
    "    label = \"or\"\n",
    "    people_O = list(set(Objects).intersection(people_O))\n",
    "    people = \", \".join(Subjects + people_O + [Subject2])\n",
    "    places = list(set(Objects + [Object2]).intersection(places + [place2]))\n",
    "    Subjects = \", \".join(Subjects + [Subject2])\n",
    "    Objects = \", \".join(Objects + [Object2])\n",
    "    places = \", \".join(places)\n",
    "    ids.sort()\n",
    "    ids = \", \".join(map(lambda x: str(x), ids))\n",
    "\n",
    "    return sentence1, sentence2, sentence2_masked, label, Subjects, Objects, ids, people, places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Raul has visited El Centro, Darren has visited Greg.',\n",
       " \"Neil didn't visit Dwayne or Raul has visited El Centro\",\n",
       " \"Neil didn't visit Dwayne [MASK] Raul has visited El Centro\",\n",
       " 'or',\n",
       " 'Raul, Darren, Neil',\n",
       " 'El Centro, Greg, Dwayne',\n",
       " '0',\n",
       " 'Raul, Darren, Greg, Neil',\n",
       " 'El Centro')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_entailment(person_list=male_names,\n",
    "               place_list=cities_and_states,\n",
    "               n=2,\n",
    "               vi_function=vi,\n",
    "               not_vi_function=not_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(out_path,\n",
    "               size,\n",
    "               type1_instances_list,\n",
    "               type2_instances_list,\n",
    "               person_list,\n",
    "               place_list,\n",
    "               n,\n",
    "               min_n):\n",
    "\n",
    "    sentence1 = []\n",
    "    sentence2 = []\n",
    "    sentence2_masked = []\n",
    "    label = []\n",
    "    subjects = []\n",
    "    objects = []\n",
    "    ids = []\n",
    "    people = []\n",
    "    places = []\n",
    "\n",
    "    type1_examples = int(size / 2)\n",
    "    type2_examples = int(size / 2)\n",
    "    type1_len = len(type1_instances_list)\n",
    "    type2_len = len(type2_instances_list)\n",
    "    type1s = [int(type1_examples / type1_len) for _ in type1_instances_list]  # noqa\n",
    "    type2s = [int(type2_examples / type2_len) for _ in type2_instances_list]  # noqa\n",
    "\n",
    "    for i, f in zip(type1s, type1_instances_list):\n",
    "        for _ in range(i):\n",
    "            current_n = np.random.choice(range(min_n, n + 1))\n",
    "            s1, s2, s2_m, l, s, o, id_, pe, pl = f(person_list, place_list, current_n)  # noqa\n",
    "            sentence1.append(s1)\n",
    "            sentence2.append(s2)\n",
    "            sentence2_masked.append(s2_m)\n",
    "            label.append(l)\n",
    "            subjects.append(s)\n",
    "            objects.append(o)\n",
    "            ids.append(id_)\n",
    "            people.append(pe)\n",
    "            places.append(pl)\n",
    "\n",
    "    for i, f in zip(type2s, type2_instances_list):\n",
    "        for _ in range(i):\n",
    "            current_n = np.random.choice(range(min_n, n + 1))\n",
    "            s1, s2, s2_m, l, s, o, id_, pe, pl = f(person_list, place_list, current_n)  # noqa\n",
    "            sentence1.append(s1)\n",
    "            sentence2.append(s2)\n",
    "            sentence2_masked.append(s2_m)\n",
    "            label.append(l)\n",
    "            subjects.append(s)\n",
    "            objects.append(o)\n",
    "            ids.append(id_)\n",
    "            people.append(pe)\n",
    "            places.append(pl)\n",
    "\n",
    "    df = pd.DataFrame({\"sentence1\": sentence1,\n",
    "                       \"sentence2\": sentence2,\n",
    "                       \"sentence2_masked\": sentence2_masked,\n",
    "                       \"label\": label,\n",
    "                       \"subjects\": subjects,\n",
    "                       \"objects\": objects,\n",
    "                       \"ids\": ids,\n",
    "                       \"people\": people,\n",
    "                       \"places\": places})\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df.to_csv(out_path, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i2eng(f):\n",
    "    return lambda x, y, z: f(x, y, z, vi_function=vi, not_vi_function=not_vi)  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv(out_path='data/generation/BC_train.csv',\n",
    "           size=10000,\n",
    "           type1_instances_list=[i2eng(and_entailment)],\n",
    "           type2_instances_list=[i2eng(or_entailment)],\n",
    "           person_list=male_names,\n",
    "           place_list=cities_and_states,\n",
    "           n=2,\n",
    "           min_n=2)\n",
    "\n",
    "create_csv(out_path='data/generation/BC_test.csv',\n",
    "           size=1000,\n",
    "           type1_instances_list=[i2eng(and_entailment)],\n",
    "           type2_instances_list=[i2eng(or_entailment)],\n",
    "           person_list=female_names,\n",
    "           place_list=countries,\n",
    "           n=2,\n",
    "           min_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_txt(in_path,\n",
    "                     out_path):\n",
    "    df = pd.read_csv(in_path)\n",
    "    ps = df[\"sentence1\"].values\n",
    "    hs = df[\"sentence2\"].values\n",
    "    with open(out_path, \"w\") as file:\n",
    "        for p,h in zip(ps, hs):\n",
    "            line = p + \"\\n\" + h + \"\\n\"\n",
    "            file.write(line)\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_train_txt(in_path='data/generation/BC_train.csv',\n",
    "                 out_path='data/generation/BC_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

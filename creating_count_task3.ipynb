{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count task:\n",
    "\n",
    "- p = $\\varphi_1, \\dots, \\varphi_m$, x visited $p_1 , \\dots, p_n$\n",
    "- h = x visited at least [mask] places\n",
    "    - [mask] = $n$ \n",
    "\n",
    "#### In this notebook we will create a df with columns 'sentence1', 'sentence2', 'sentence2_masked' 'label', and a txt for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from inference.text_generation.vocab import male_names, female_names, cities_and_states, countries\n",
    "from inference.text_generation.util import get_new_item, get_n_different_items\n",
    "from inference.text_generation.util import vi, not_vi, num2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entailment(person_list,\n",
    "                     place_list,\n",
    "                     n,\n",
    "                     number_of_other_sentences,\n",
    "                     vi_function,\n",
    "                     not_vi_function,\n",
    "                     number2str,\n",
    "                     complement,\n",
    "                     mask_token=\"[MASK]\",\n",
    "                     replace_symbol=\"%\"):\n",
    "    \"\"\"\n",
    "    $P:= S_1, dots, S_m, V(x, p_1) , dots, pm V(x, p_n)$\n",
    "    $H:= x$ has visited at least $n$ places\n",
    "    \n",
    "    S_j can be not V(x, p*)\n",
    "    \"\"\"\n",
    "    m = number_of_other_sentences\n",
    "    Subjects = get_n_different_items(person_list, m + 1)\n",
    "    Objects = get_n_different_items(place_list, n + m)\n",
    "    Subjects_before = Subjects[:m]\n",
    "    Subjects_after = Subjects[m:] * n\n",
    "    Objects_before = Objects[:m]\n",
    "    Objects_after = Objects[m:]\n",
    "    fs_before = np.random.choice([vi_function, not_vi_function], m)\n",
    "    fs_after = [vi_function] * n\n",
    "    \n",
    "    add_Subjects_after_before = np.random.choice([True, False])\n",
    "    \n",
    "    if add_Subjects_after_before:\n",
    "        Subjects.remove(Subjects_before[0])\n",
    "        Subjects_before[0] = Subjects_after[0]\n",
    "        fs_before[0] = not_vi_function\n",
    "        \n",
    "    sentence1_before = [f(x, y) for f, x, y in zip(fs_before, Subjects_before, Objects_before)]\n",
    "    sentence1_after =  [f(x, y) for f, x, y in zip(fs_after, Subjects_after, Objects_after)]\n",
    "    sentence1 = sentence1_before + sentence1_after\n",
    "    indicator = vi_function(Subjects_after[0], \"x\")[:-1]\n",
    "    np.random.shuffle(sentence1)\n",
    "    ids = [i for i,s in enumerate(sentence1) if indicator in s]\n",
    "    sentence1 = \", \".join(sentence1)\n",
    "    sentence1 += \".\" \n",
    "    numeral = number2str[n]\n",
    "    complement_true = complement.replace(replace_symbol, numeral)\n",
    "    complement_masked = complement.replace(replace_symbol, mask_token)\n",
    "    sentence2 = vi_function(Subjects_after[0], complement_true)\n",
    "    sentence2_masked = vi_function(Subjects_after[0], complement_masked)\n",
    "    label = numeral\n",
    "    people = \", \".join(Subjects)\n",
    "    Subjects = \", \".join(Subjects)\n",
    "    Objects = \", \".join(Objects)\n",
    "    places = Objects\n",
    "    ids = \", \".join(map(lambda x: str(x), ids))\n",
    "\n",
    "    return sentence1, sentence2, sentence2_masked, label, Subjects, Objects, ids, people, places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Jerome has visited Campbellsville, Jerome has visited Spring Green, Jerome has visited Park Ridge, Jerome didn't visit Demopolis, Jerome has visited Pagosa Springs.\",\n",
       " 'Jerome has visited at least four places',\n",
       " 'Jerome has visited at least [MASK] places',\n",
       " 'four',\n",
       " 'Jerome',\n",
       " 'Demopolis, Spring Green, Park Ridge, Campbellsville, Pagosa Springs',\n",
       " '0, 1, 2, 4',\n",
       " 'Jerome',\n",
       " 'Demopolis, Spring Green, Park Ridge, Campbellsville, Pagosa Springs')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_entailment(person_list=male_names,\n",
    "                 place_list=cities_and_states,\n",
    "                 n=4,\n",
    "                 number_of_other_sentences=1,\n",
    "                 vi_function=vi,\n",
    "                 not_vi_function=not_vi,\n",
    "                 number2str=num2word,\n",
    "                 complement=\"at least % places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i2eng(f, m):\n",
    "    return lambda x, y, z: f(x,\n",
    "                             y,\n",
    "                             z,\n",
    "                             number_of_other_sentences=m,\n",
    "                             vi_function=vi,\n",
    "                             not_vi_function=not_vi,\n",
    "                             number2str=num2word,\n",
    "                             complement=\"at least % places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_instances_list = [i2eng(count_entailment, 1), i2eng(count_entailment, 2), i2eng(count_entailment, 3), i2eng(count_entailment, 4)]\n",
    "type2_instances_list = [i2eng(count_entailment, 5), i2eng(count_entailment, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(out_path,\n",
    "               size,\n",
    "               type1_instances_list,\n",
    "               type2_instances_list,\n",
    "               person_list,\n",
    "               place_list,\n",
    "               n,\n",
    "               min_n):\n",
    "\n",
    "    sentence1 = []\n",
    "    sentence2 = []\n",
    "    sentence2_masked = []\n",
    "    label = []\n",
    "    subjects = []\n",
    "    objects = []\n",
    "    ids = []\n",
    "    people = []\n",
    "    places = []\n",
    "\n",
    "    type1_examples = int(size / 2)\n",
    "    type2_examples = int(size / 2)\n",
    "    type1_len = len(type1_instances_list)\n",
    "    type2_len = len(type2_instances_list)\n",
    "    type1s = [int(type1_examples / type1_len) for _ in type1_instances_list]  # noqa\n",
    "    type2s = [int(type2_examples / type2_len) for _ in type2_instances_list]  # noqa\n",
    "\n",
    "    for i, f in zip(type1s, type1_instances_list):\n",
    "        for _ in range(i):\n",
    "            current_n = np.random.choice(range(min_n, n + 1))\n",
    "            s1, s2, s2_m, l, s, o, id_, pe, pl = f(person_list, place_list, current_n)  # noqa\n",
    "            sentence1.append(s1)\n",
    "            sentence2.append(s2)\n",
    "            sentence2_masked.append(s2_m)\n",
    "            label.append(l)\n",
    "            subjects.append(s)\n",
    "            objects.append(o)\n",
    "            ids.append(id_)\n",
    "            people.append(pe)\n",
    "            places.append(pl)\n",
    "\n",
    "    for i, f in zip(type2s, type2_instances_list):\n",
    "        for _ in range(i):\n",
    "            current_n = np.random.choice(range(min_n, n + 1))\n",
    "            s1, s2, s2_m, l, s, o, id_, pe, pl = f(person_list, place_list, current_n)  # noqa\n",
    "            sentence1.append(s1)\n",
    "            sentence2.append(s2)\n",
    "            sentence2_masked.append(s2_m)\n",
    "            label.append(l)\n",
    "            subjects.append(s)\n",
    "            objects.append(o)\n",
    "            ids.append(id_)\n",
    "            people.append(pe)\n",
    "            places.append(pl)\n",
    "\n",
    "    df = pd.DataFrame({\"sentence1\": sentence1,\n",
    "                       \"sentence2\": sentence2,\n",
    "                       \"sentence2_masked\": sentence2_masked,\n",
    "                       \"label\": label,\n",
    "                       \"subjects\": subjects,\n",
    "                       \"objects\": objects,\n",
    "                       \"ids\": ids,\n",
    "                       \"people\": people,\n",
    "                       \"places\": places})\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df.to_csv(out_path, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv(out_path='data/generation/count_train.csv',\n",
    "           size=10000,\n",
    "           type1_instances_list=type1_instances_list,\n",
    "           type2_instances_list=type2_instances_list,\n",
    "           person_list=male_names,\n",
    "           place_list=cities_and_states,\n",
    "           n=20,\n",
    "           min_n=1)\n",
    "\n",
    "create_csv(out_path='data/generation/count_test.csv',\n",
    "           size=1000,\n",
    "           type1_instances_list=type1_instances_list,\n",
    "           type2_instances_list=type2_instances_list,\n",
    "           person_list=female_names,\n",
    "           place_list=countries,\n",
    "           n=20,\n",
    "           min_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_txt(in_path,\n",
    "                     out_path):\n",
    "    df = pd.read_csv(in_path)\n",
    "    ps = df[\"sentence1\"].values\n",
    "    hs = df[\"sentence2\"].values\n",
    "    with open(out_path, \"w\") as file:\n",
    "        for p,h in zip(ps, hs):\n",
    "            line = p + \"\\n\" + h + \"\\n\"\n",
    "            file.write(line)\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_train_txt(in_path='data/generation/count_train.csv',\n",
    "                 out_path='data/generation/count_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
